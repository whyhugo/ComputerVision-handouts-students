{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Deep Learning: Computer Vision with Pre-train Model\n",
    "> AHSNCCU/NTNU CSIE ç‹ä¿®ä½‘"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ æ¢ç´¢å¯ç”¨æ¨¡å‹ğŸ‘‰ [NGC](https://ngc.nvidia.com/catalog/models)\n",
    "+ GitHub\n",
    "+ Google Search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Practice: è‡ªå‹•åŒ–ç‹—é–€"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ å½±åƒåˆ†é¡æ¨¡å‹ğŸ‘‰ [ImageNet æŒ‘æˆ°](https://en.wikipedia.org/wiki/ImageNet#History_of_the_ImageNet_challenge)\n",
    "+ ç¶“éå¤§å‹datasetè¨“ç·´\n",
    "+ å¤§å¤šé‡å°è²“ç‹—å‹•ç‰©\n",
    "+ 1000é¡åˆ¥\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## è¼‰å…¥æ¨¡å‹"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "å¾Kerasè¼‰å…¥[ImageNetæ¨¡å‹](https://keras.io/api/applications/#available-models)\n",
    "é¦–å…ˆæˆ‘å€‘è¦ä¸‹è¼‰æ¨¡å‹ã€‚ç¶“éè¨“ç·´çš„ ImageNet æ¨¡å‹å¯ä»¥ç›´æ¥åœ¨ Keras å‡½å¼åº«ä¸­ä¸‹è¼‰ã€‚\n",
    "\n",
    "+ [VGG16](https://keras.io/api/applications/vgg/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import VGG16\n",
    "  \n",
    "# load the VGG16 network *pre-trained* on the ImageNet dataset\n",
    "model = VGG16(weights=\"imagenet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "æ³¨æ„Input Layer & Output Layeræ˜¯å¦ç¬¦åˆæˆ‘å€‘çš„ç¶­åº¦éœ€æ±‚ï¼"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### è¼¸å…¥ç¶­åº¦\n",
    "åœ–åƒæ ¼å¼: (224, 224, 3)  \n",
    "å–®å¼µè¼¸å…¥æ ¼å¼: (1, 224, 224, 3)\n",
    "\n",
    "### è¼¸å‡ºç¶­åº¦\n",
    "Output Layerçš„shapeç‚º 1000ğŸ‘‰classæ•¸é‡ã€‚  \n",
    "[ImageNeté¡åˆ¥](https://gist.github.com/yrevar/942d3a0ac09ec9e5eb3a)\n",
    "\n",
    "+ ç‹—çš„ç¯„åœç‚ºé¡åˆ¥ 151 åˆ° 268\n",
    "+ è²“çš„ç¯„åœç‚ºé¡åˆ¥ 281 åˆ° 285"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## è¼‰å…¥å½±åƒ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "def show_image(image_path):\n",
    "    image = mpimg.imread(image_path)\n",
    "    print(image.shape)\n",
    "    plt.imshow(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_image(\"doggy_door_images/happy_dog.jpg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## é å…ˆè™•ç†å½±åƒ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "å½±åƒçš„æœ€çµ‚å½¢ç‹€å¿…é ˆæ˜¯ (1, 224, 224, 3)\n",
    "+ Keras[`preprocess_input`æ–¹æ³•](https://www.tensorflow.org/api_docs/python/tf/keras/applications/vgg16/preprocess_input)ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing import image as image_utils\n",
    "from tensorflow.keras.applications.vgg16 import preprocess_input\n",
    "\n",
    "def load_and_process_image(image_path):\n",
    "    # Print image's original shape, for reference\n",
    "    print('Original image shape: ', mpimg.imread(image_path).shape)\n",
    "    \n",
    "    # Load in the image with a target size of 224, 224\n",
    "    image = image_utils.load_img(image_path, target_size=(224, 224))\n",
    "    # Convert the image from a PIL format to a numpy array\n",
    "    image = image_utils.img_to_array(image)\n",
    "    # Add a dimension for number of images, in our case 1\n",
    "    image = image.reshape(1,224,224,3)\n",
    "    # Preprocess image to align with original ImageNet dataset\n",
    "    image = preprocess_input(image)\n",
    "    # Print image's shape after processing\n",
    "    print('Processed image shape: ', image.shape)\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "processed_image = load_and_process_image(\"doggy_door_images/brown_bear.jpg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## é€²è¡Œé æ¸¬"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.vgg16 import decode_predictions\n",
    "\n",
    "def readable_prediction(image_path):\n",
    "    # Show image\n",
    "    show_image(image_path)\n",
    "    # Load and pre-process image\n",
    "    image = load_and_process_image(image_path)\n",
    "    # Make predictions\n",
    "    predictions = model.predict(image)\n",
    "    # Print predictions in readable form\n",
    "    print('Predicted:', decode_predictions(predictions, top=3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ç”¨å¹¾ç¨®å‹•ç‰©è©¦è©¦çœ‹ï¼Œç„¶å¾Œçœ‹çœ‹çµæœå¦‚ä½•ï¼ä¹Ÿæ­¡è¿ä½ ä¸Šå‚³è‡ªå·±çš„å½±åƒä¸¦åˆ†é¡ï¼Œçœ‹çœ‹æ¨¡å‹çš„è¡¨ç¾æœ‰å¤šå¥½ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "readable_prediction(\"doggy_door_images/happy_dog.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "readable_prediction(\"doggy_door_images/brown_bear.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "readable_prediction(\"doggy_door_images/sleepy_cat.jpg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## åƒ…é™ç‹—"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ ç‹—çš„ç¯„åœæ˜¯é¡åˆ¥ 151 è‡³ 268\n",
    "+ è²“çš„ç¯„åœæ˜¯é¡åˆ¥ 281 è‡³ 285\n",
    "+ é‹ç”¨ [argmax](https://numpy.org/doc/stable/reference/generated/numpy.argmax.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def doggy_door(image_path):\n",
    "    show_image(image_path)\n",
    "    image = load_and_process_image(image_path)\n",
    "    preds = model.predict(image)\n",
    "    if 151 <= np.argmax(preds) <= 268:\n",
    "        print(\"Doggy come on in!\")\n",
    "    elif 281 <= np.argmax(preds) <= 285:\n",
    "        print(\"Kitty stay inside!\")\n",
    "    else:\n",
    "        print(\"You're not a dog! Stay outside!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doggy_door(\"doggy_door_images/brown_bear.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doggy_door(\"doggy_door_images/happy_dog.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doggy_door(\"doggy_door_images/sleepy_cat.jpg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### æ¸…é™¤è¨˜æ†¶é«”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import IPython\n",
    "app = IPython.Application.instance()\n",
    "app.kernel.do_shutdown(True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
