{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 部署模型\n",
    "現在我們的模型已經過完整訓練，派上用場的時候到了。在本練習中，我們會讓模型讀取新影像，並偵測手語字母表中的正確字母。現在就開始吧！"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 目標"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 從磁碟載入經過訓練的模型\n",
    "* 重新格式化影像以適用於以不同格式影像進行訓練的模型\n",
    "* 讓經過訓練的模型推論未見過的新影像，並且評估其效能"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 載入模型\n",
    "現在我們使用的是新的 Notebook，所以我們要載入之前訓練過並儲存的模型。我們在先前的練習儲存模型時，建立了一個名稱為 \"asl_model\" 的資料夾。只要選取相同的資料夾就可以載入模型。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "\n",
    "model = keras.models.load_model('asl_model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如果你想要確保一切都沒有變動，可以再次查看模型的摘要。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 為模型準備影像"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "現在要開始使用模型對先前從未見過的全新影像進行預測。這個過程也稱為推論。我們在 asl_images 資料夾中提供了一組影像。請試著用左側導覽面板開啟並探索影像。\n",
    "\n",
    "你應該會發現，眼前影像的解析度比資料集中的影像高出許多，而且是彩色的。請記得，資料集中的影像是 28x28 像素和灰階。請務必要記得，每次使用模型進行預測時，輸入內容的形狀必須與模型的訓練資料的形狀相符。以這個模型而言，訓練資料集的形狀為：(27455, 28, 28, 1)。意思是有 27,455 張 28x28 像素的影像，每一張皆為單一色頻 (灰階)。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 顯示影像"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "當我們使用模型對新影像進行預測，同時顯示影像會很有幫助。我們可以使用 matplotlib 函式庫做到這一點。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "def show_image(image_path):\n",
    "    image = mpimg.imread(image_path)\n",
    "    plt.imshow(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_image('asl_images/b.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 調整影像"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "資料集中的影像是 28x28 像素和灰階。我們必須確保傳遞給預測方法的影像也是相同的大小和色彩。有幾種方法可以透過 Python 編輯影像，不過 Keras 的內建公用程式也有同樣的功能。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing import image as image_utils\n",
    "\n",
    "def load_and_scale_image(image_path):\n",
    "    image = image_utils.load_img(image_path, color_mode=\"grayscale\", target_size=(28,28))\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = load_and_scale_image('asl_images/b.png')\n",
    "plt.imshow(image, cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 準備用於預測的影像"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "現在我們有 28x28 像素的灰階影像，很快就能準備好將影像傳遞到模型中以進行預測。首先，我們需要重新調整影像，以符合用於訓練模型的資料集形狀。在重新調整前，我們需要將影像轉換成更原始的格式。我們要使用名為 image_to_array 的 Keras 公用程式來進行這項操作。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = image_utils.img_to_array(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "現在我們可以重新調整影像，為預測做好準備。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This reshape corresponds to 1 image of 28x28 pixels with one color channel\n",
    "image = image.reshape(1,28,28,1) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "最後，務必要記得正規化資料 (讓所有值都介於 0-1)，就像我們在處理訓練資料集一樣："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = image / 255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 進行預測\n",
    "\n",
    "現在，我們已經準備好進行預測了！方法是將經過前置處理的影像傳遞至模型的預測方法。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = model.predict(image)\n",
    "print(prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 瞭解預測過程"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "預測的格式為 24 長度陣列。儘管看起來有點不同，這個格式和 y_train 與 y_test 的「binarized」分類陣列格式相同。陣列中的每個元素都是介於 0 和 1 的機率，表示每個類別的可信度。讓我們用更容易理解的方式說明。首先我們可以找出陣列中哪個元素代表最高的機率。運用 Numpy 函式庫和 [argmax](https://numpy.org/doc/stable/reference/generated/numpy.argmax.html) 函數就能輕易做到這一點。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.argmax(prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "預測陣列的每個元素都代表手語字母表中的一個可能字母。別忘了，j 和 z 不是選項，因為表達這兩個字母需要移動手部，但我們只有處理靜態相片。讓我們在預測陣列的索引和對應的字母之間建立對應。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alphabet does not contain j or z because they require movement\n",
    "alphabet = \"abcdefghiklmnopqrstuvwxy\"\n",
    "dictionary = {}\n",
    "for i in range(24):\n",
    "    dictionary[i] = alphabet[i]\n",
    "dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "現在我們可以傳遞預測索引來找出對應的字母。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary[np.argmax(prediction)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 練習：整合所有過程"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "讓我們把所有過程都放入函數，就可以從影像檔案直接進行預測。使用上述的函數和步驟，並在下方的函數中實作。如果需要協助，請按一下下方的三個點以顯示解決方案。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_letter(file_path):\n",
    "    # Show image\n",
    "    FIXME\n",
    "    # Load and scale image\n",
    "    image = FIXME\n",
    "    # Convert to array\n",
    "    image = FIXME\n",
    "    # Reshape image\n",
    "    image = FIXME\n",
    "    # Normalize image\n",
    "    image = FIXME\n",
    "    # Make prediction\n",
    "    prediction = FIXME\n",
    "    # Convert prediction to letter\n",
    "    predicted_letter = FIXME\n",
    "    # Return prediction\n",
    "    return predicted_letter   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 解決方案"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "按一下以下的「...」來檢視解決方案。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "```python\n",
    "def predict_letter(file_path):\n",
    "    show_image(file_path)\n",
    "    image = load_and_scale_image(file_path)\n",
    "    image = image_utils.img_to_array(image)\n",
    "    image = image.reshape(1,28,28,1) \n",
    "    image = image/255\n",
    "    prediction = model.predict(image)\n",
    "    # convert prediction to letter\n",
    "    predicted_letter = dictionary[np.argmax(prediction)]\n",
    "    return predicted_letter\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_letter(\"asl_images/b.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "讓我們也測試看看 asl_images 資料集中的字母「a」資料："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_letter(\"asl_images/a.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 摘要"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "你在練習中表現得很好！你已經完成了整個流程：從頭開始訓練高度精確的模型，接著使用模型進行全新且有意義的預測。如果你還有時間，建議你使用網路攝影機拍攝圖片，並拖曳到 asl_data 資料夾上傳，然後用來測試模型。如果你是 Mac 使用者，可以使用 Photo Booth。如果你是 Windows 使用者，你可以從「開始」畫面選取相機應用程式。我們希望你可以試試看。這可是學些手語的好機會！例如，用你的姓名拼音字母試試看。\n",
    "\n",
    "我們可以想像到要如何在應用程式中使用這個模型，例如教人學手語，甚至協助無法說話的人與電腦互動。如果你很熟悉網路開發，甚至可以透過 [TensorFlow](https://www.tensorflow.org/js) 這個函式庫在瀏覽器中使用模型。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 清除記憶體"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在繼續之前，請執行下列儲存格以清除 GPU 記憶體。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import IPython\n",
    "app = IPython.Application.instance()\n",
    "app.kernel.do_shutdown(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 下一步"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "希望你喜歡這些練習！在接下來的章節中，我們要學習如何在沒有可靠的資料集時善用深度學習。到時候見了！\n",
    "若要深入瞭解邊緣端推論，請參閱有關這項主題的[精彩白皮書](http://web.eecs.umich.edu/~mosharaf/Readings/FB-ML-Edge.pdf)。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "現在你已經熟悉要如何建立自己的模型，也稍微瞭解這些模型的運作方式，接下來我們會把重點放在非常強大的技術，也就是使用預先訓練的模型來加速作業。請繼續前往下一節：[*預先訓練的模型*](./05a_doggy_door.ipynb)。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
